{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 이번에 새로운 문제"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 첨부된 노트북 파일 (AI_BU_02.ipynb) 에 실행된 결과 화면이 나오도록 코드 셀에 있는 (1), (2), (3), (4), (5), (6), 를 알맞게 수정 및 채워넣고 수정한 이유를 코드 내에 주석으로 적어 AI_BU_.ipaynb 파일을 기간 내에 제출하시오 (단, 위 여섯 부분만 수정할 것)\n",
        "\n",
        "## 목표 레이블의 값이 0일 경우 final predictions 값이 0.5미만, 목표 레이블의 값이 1일 경우 **final predictions** 값이 0.5 이상일 경우에만 정답처리할 것."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [루브릭]\n",
        "\n",
        "- 1점 : 위 지시 사항을 만족하여 기간 내에 파일을 제출한 경우\n",
        "- 0점 :미제출, 지각제출, 결과 화면과 다른 결과가 나오는 경우, AI_BU_02.ipynb 파일의 다른 부분을 수정한 경우, AI_BU_02.ipynb이 아닌 다른 파일을 제출한 경우\n",
        "- -1점 : 다른 사람의 파일을 그대로 제출한 경우(의심이 되는 코드인 경우 제대로 소명이 안되면 -1점을 드립니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss = 0.5177932357137532\n",
            "Epoch 1000: Loss = 0.16498330261488103\n",
            "Epoch 2000: Loss = 0.08672735509353234\n",
            "Epoch 3000: Loss = 0.047841385624963234\n",
            "Epoch 4000: Loss = 0.022843198930963524\n",
            "Epoch 5000: Loss = 0.010000579148433058\n",
            "Epoch 6000: Loss = 0.005574493034532012\n",
            "Epoch 7000: Loss = 0.003702930872473331\n",
            "Epoch 8000: Loss = 0.0027253156785937635\n",
            "Epoch 9000: Loss = 0.0021381732970850286\n",
            "\n",
            "Final predictions:\n",
            "[[0.00115531]\n",
            " [0.03567474]\n",
            " [0.04509549]\n",
            " [0.93920266]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 시그모이드 활성화 함수 및 미분 함수 정의\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# 신경망 아키텍처 정의\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "\n",
        "# 신경망의 가중치 초기화\n",
        "np.random.seed(0)\n",
        "weights_input_hidden = np.random.uniform(size=(input_size, hidden_size))\n",
        "weights_hidden_output = np.random.uniform(size=(hidden_size, output_size))\n",
        "\n",
        "# 입력 데이터 (AND 논리 연산)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "# 목표 레이블 (AND 논리 연산 결과)\n",
        "'''(1)'''\n",
        "y = np.array([[0], [0], [0], [1]]) # X의 각 값의 and 논리 연산 결과\n",
        "\n",
        "# 학습 하이퍼파라미터 설정\n",
        "learning_rate = 0.1 # 예시와 같은 결과를 갖기위한 적절한 값\n",
        "num_epochs = 10000 # 예시와 같은 결과를 갖기위한 적절한 값\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward propagation (순방향 전파)\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output_layer_output = sigmoid(output_layer_input)\n",
        "\n",
        "    # 손실 계산 (평균 제곱 오차)\n",
        "    loss = np.mean((y - output_layer_output) ** 2)\n",
        "\n",
        "    # Backpropagation (역전파)\n",
        "    # 출력 레이어의 그래디언트 계산\n",
        "    output_error = y - output_layer_output\n",
        "    output_delta = output_error * sigmoid_derivative(output_layer_input) # 출력 레이어의 그래디언트를 구하기 위해, 출력 레이어의 입력값의 sigmoid_derivative 값을 곱함\n",
        "\n",
        "    # 은닉 레이어로 오차 전파\n",
        "    hidden_layer_error = output_delta.dot(weights_hidden_output.T)\n",
        "    hidden_layer_delta = hidden_layer_error * sigmoid_derivative(hidden_layer_input) # 은닉 레이어의 그래디언트를 구하기 위해, 은닉 레이어의 입력값의 sigmoid_derivative 값을 곱함\n",
        "\n",
        "    # 가중치 업데이트\n",
        "    weights_hidden_output += hidden_layer_output.T.dot(output_delta) * learning_rate\n",
        "    weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n",
        "\n",
        "    # 1000 에포크마다 손실 출력\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss}\")\n",
        "\n",
        "# 학습 후, 예측 수행\n",
        "final_hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "final_hidden_layer_output = sigmoid(final_hidden_layer_input)\n",
        "final_output_layer_input = np.dot(final_hidden_layer_output, weights_hidden_output)\n",
        "final_output_layer_output = sigmoid(final_output_layer_input)\n",
        "\n",
        "print(\"\\nFinal predictions:\")\n",
        "print(final_output_layer_output) # 각 레이블의 최종적인 예측값\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
